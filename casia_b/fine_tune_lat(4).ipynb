{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import copy\n",
    "plt.ion()\n",
    "\n",
    "from loess import Loess\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 125\n",
    "\n",
    "#pretrained model\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "#change last layer\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "print(num_ftrs)\n",
    "model_conv.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "#load model\n",
    "PATH = \"/home/nirbhay/tharun/casia_b/rs18_nm14_ft_fe.pth\"\n",
    "model_conv.load_state_dict(torch.load(PATH,map_location='cpu'))\n",
    "model_conv.eval()\n",
    "\n",
    "# Use the model object to select the desired layer\n",
    "layer = model_conv._modules.get('avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_name):\n",
    "    # 1. Load the image with Pillow library\n",
    "    img = Image.open(image_name)    \n",
    "    img = img.convert('RGB')\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))    \n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)    \n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data[0,:,0,0])    \n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)    \n",
    "    # 6. Run the model on our transformed image\n",
    "    model_conv(t_img)   \n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()   \n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "with open(\"indices_gait.txt\", \"rb\") as fl:\n",
    "    ind = pickle.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gait energy --helper function\n",
    "def find_gait(path,app,nm):\n",
    "    files = glob.glob(path+\"*.png\")\n",
    "    files.sort()\n",
    "    \n",
    "    path = \"/DATA/nirbhay/tharun/gei/\"+app\n",
    "    if os.path.isdir(path) == False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    num_gait=0\n",
    "    for j in range(len(ind[int(app)][nm-1])-2):\n",
    "        if j is None:\n",
    "            continue\n",
    "        c=0\n",
    "        #all images in gait cycle\n",
    "        gei_img = np.zeros((150,75))\n",
    "        vec = []\n",
    "        for i in range(ind[int(app)][nm-1][j],ind[int(app)][nm-1][j+2]+1):\n",
    "            vec.append(get_vector(files[i]).numpy())\n",
    "            #predict missing latent vector\n",
    "        num_gait+=1\n",
    "        vec = np.array(vec)\n",
    "        v = vec.mean(0)\n",
    "        x.append(v)\n",
    "        y.append(int(app))\n",
    "    print(f\"num_gaits {num_gait}\")\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gait energy images\n",
    "for i in range(1,125):\n",
    "    if i<10:\n",
    "        app = \"00\"+str(i)\n",
    "    elif i<100:\n",
    "        app = \"0\"+str(i)\n",
    "    else :\n",
    "        app = str(i)\n",
    "    for j in range(1,5):\n",
    "        path = \"/DATA/nirbhay/tharun/dataset_CASIA/\"+app+\"/nm-0\"+str(j)+\"/\"\n",
    "        print(f\"person {app} nm {j}\")\n",
    "        find_gait(path,app,j)\n",
    "    print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"feature_vects_lat.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(x, fp)\n",
    "    \n",
    "with open(\"feature_vects_lat.txt\", \"rb\") as fp:   # Unpickling\n",
    "    nx = pickle.load(fp)\n",
    "\n",
    "with open(\"feature_vects_lab.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y, fp)\n",
    "    \n",
    "with open(\"feature_vects_lab.txt\", \"rb\") as fp:   # Unpickling\n",
    "    ny = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size=0.2, random_state=101, stratify=y)\n",
    "dfs = {'train':(x_train,y_train),'val':(x_val,y_val)}\n",
    "len(x_train), len(y_train), len(x_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset\n",
    "class casia(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        lat_vec = torch.tensor(self.x[index])\n",
    "        label = torch.tensor(self.y[index])\n",
    "        return lat_vec,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    x : casia(dfs[x][0],dfs[x][1])\n",
    "    for x in ['train','val']\n",
    "}\n",
    "\n",
    "dataloaders = {x: DataLoader(datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']\n",
    "              }\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "num_classes = 125\n",
    "class_names = [i for i in range(1,125)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train' and scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 125\n",
    "model_res = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# # Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "PATH = \"/home/nirbhay/tharun/casia_b/rs18_nm14_ft_fe.pth\"\n",
    "model_res.load_state_dict(torch.load(PATH))\n",
    "model_res = model_res.eval()\n",
    "\n",
    "class latent_vect(nn.Module):\n",
    "    def __init__(self,in_sz,out_sz):\n",
    "        super(latent_vect, self).__init__()\n",
    "        self.fc = nn.Linear(in_sz,out_sz)\n",
    "    def forward(self,x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "model_lat = latent_vect(512,125)\n",
    "\n",
    "#copying weights from resnet for better convergence\n",
    "params1 = model_res.named_parameters()\n",
    "params2 = model_lat.named_parameters()\n",
    "\n",
    "dict_params2 = dict(params2)\n",
    "\n",
    "for name1, param1 in params1:\n",
    "    if name1 in dict_params2:\n",
    "        dict_params2[name1].data.copy_(param1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_lat = model_lat.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#all params\n",
    "optimizer_conv = optim.SGD(model_lat.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=15, gamma=0.1)\n",
    "# exp_lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40\n",
    "model_lat = train_model(model_lat, criterion, optimizer_conv,exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/nirbhay/tharun/casia_b/lt_fe_ft.pth\"\n",
    "torch.save(model_lat.state_dict(),PATH)\n",
    "model_lat.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
